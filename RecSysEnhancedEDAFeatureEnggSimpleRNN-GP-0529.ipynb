{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d1fd2ab5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing and Helper Functions\n",
    "# First, let's set up the preprocessing and helper functions that will be used by the RecSys models.\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from datetime import timedelta\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "21c0c9ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "train_data = pd.read_csv('train_set.csv')\n",
    "fraction_of_data_to_use = 0.01   \n",
    "train_data = train_data.sample(frac=fraction_of_data_to_use)\n",
    "\n",
    "# Convert date columns to datetime format\n",
    "train_data['checkin'] = pd.to_datetime(train_data['checkin'])\n",
    "train_data['checkout'] = pd.to_datetime(train_data['checkout'])\n",
    "\n",
    "# Sort the data by user trip ID and check-in date to maintain the chronological order\n",
    "train_data.sort_values(by=['utrip_id', 'checkin'], inplace=True)\n",
    "\n",
    "# Create a city_country column\n",
    "train_data['city_country'] = train_data['city_id'].astype(str) + '_' + train_data['hotel_country'].astype(str)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4599c4d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create city and country chains with additional features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "80fce1ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/11385 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11385/11385 [00:37<00:00, 302.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    utrip_id  user_id cities_chain countries_chain  trip_duration  \\\n",
      "0  1000643_1  1000643      [62185]       [Axphain]              2   \n",
      "1   100160_2   100160      [49540]    [Novistrana]              2   \n",
      "2  1001776_1  1001776       [4608]  [Glubbdubdrib]              1   \n",
      "3  1001838_2  1001838      [43666]      [Leutonia]              1   \n",
      "4  1002275_1  1002275      [36805]       [Alvonia]              1   \n",
      "\n",
      "  stay_durations device_classes affiliate_ids checkin_months  \\\n",
      "0            [2]      [desktop]         [384]           [10]   \n",
      "1            [2]      [desktop]        [8132]            [8]   \n",
      "2            [1]      [desktop]        [3134]            [8]   \n",
      "3            [1]      [desktop]        [9924]            [6]   \n",
      "4            [1]      [desktop]        [4541]            [9]   \n",
      "\n",
      "  checkin_days_of_week   city_country_chain  \n",
      "0                  [5]      [62185_Axphain]  \n",
      "1                  [1]   [49540_Novistrana]  \n",
      "2                  [0]  [4608_Glubbdubdrib]  \n",
      "3                  [3]     [43666_Leutonia]  \n",
      "4                  [1]      [36805_Alvonia]  \n"
     ]
    }
   ],
   "source": [
    "# Initialize tqdm for progress tracking\n",
    "tqdm.pandas()\n",
    "\n",
    "# Function to calculate trip duration\n",
    "def calculate_trip_duration(checkin, checkout):\n",
    "    return (checkout - checkin).days\n",
    "\n",
    "# Function to calculate stay duration\n",
    "def calculate_stay_duration(checkin, checkout):\n",
    "    return (checkout - checkin).days\n",
    "\n",
    "# Group by utrip_id and create the city and country chains with additional features\n",
    "trip_chains = train_data.groupby('utrip_id').progress_apply(lambda group: pd.Series({\n",
    "    'user_id': group['user_id'].iloc[0],\n",
    "    'cities_chain': list(group['city_id']),\n",
    "    'countries_chain': list(group['hotel_country']),\n",
    "    'trip_duration': calculate_trip_duration(group['checkin'].iloc[0], group['checkout'].iloc[-1]),\n",
    "    'stay_durations': list(group.apply(lambda row: calculate_stay_duration(row['checkin'], row['checkout']), axis=1)),\n",
    "    'device_classes': list(group['device_class']),\n",
    "    'affiliate_ids': list(group['affiliate_id']),\n",
    "    'checkin_months': list(group['checkin'].dt.month),\n",
    "    'checkin_days_of_week': list(group['checkin'].dt.dayofweek)\n",
    "})).reset_index()\n",
    "\n",
    "# Rename columns for clarity\n",
    "trip_chains.columns = ['utrip_id', 'user_id', 'cities_chain', 'countries_chain', 'trip_duration', 'stay_durations',\n",
    "                       'device_classes', 'affiliate_ids', 'checkin_months', 'checkin_days_of_week']\n",
    "\n",
    "# Create a new DataFrame for trip chains\n",
    "trip_chains_df = trip_chains.copy()\n",
    "\n",
    "# Add city_country chains to the DataFrame\n",
    "trip_chains_df['city_country_chain'] = trip_chains_df.apply(\n",
    "    lambda row: [f\"{city}_{country}\" for city, country in zip(row['cities_chain'], row['countries_chain'])], axis=1)\n",
    "\n",
    "# Display the first few rows of the trip_chains_df DataFrame\n",
    "print(trip_chains_df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "73d2811c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trip chains written to trip_chains_enhanced.xlsx\n"
     ]
    }
   ],
   "source": [
    "# Write the trip_chains_df DataFrame to an Excel file\n",
    "output_file = 'trip_chains_enhanced.xlsx'\n",
    "trip_chains_df.to_excel(output_file, index=False)\n",
    "print(f'Trip chains written to {output_file}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "86681829",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "next_place          10060_Novistrana  10061_Bozatta  10283_Bozatta  \\\n",
      "current_place                                                        \n",
      "10013_Fook Island                0.0            0.0            0.0   \n",
      "10064_Glubbdubdrib               0.0            0.0            0.0   \n",
      "1034_Gondal                      0.0            0.0            0.0   \n",
      "10392_El Othar                   0.0            0.0            0.0   \n",
      "1046_Glubbdubdrib                0.0            0.0            0.0   \n",
      "\n",
      "next_place          1046_Glubbdubdrib  10743_Cobra Island  10839_Gondal  \\\n",
      "current_place                                                             \n",
      "10013_Fook Island                 0.0                 0.0           0.0   \n",
      "10064_Glubbdubdrib                0.0                 0.0           0.0   \n",
      "1034_Gondal                       0.0                 0.0           0.0   \n",
      "10392_El Othar                    0.0                 0.0           0.0   \n",
      "1046_Glubbdubdrib                 0.0                 0.0           0.0   \n",
      "\n",
      "next_place          10994_Nevoruss  12308_Santa Prisca  1230_Cobra Island  \\\n",
      "current_place                                                               \n",
      "10013_Fook Island              0.0                 0.0                0.0   \n",
      "10064_Glubbdubdrib             0.0                 0.0                0.0   \n",
      "1034_Gondal                    0.0                 0.0                0.0   \n",
      "10392_El Othar                 0.0                 0.0                0.0   \n",
      "1046_Glubbdubdrib              0.0                 0.0                0.0   \n",
      "\n",
      "next_place          12426_Fook Island  ...  67169_Glubbdubdrib  67353_Elbonia  \\\n",
      "current_place                          ...                                      \n",
      "10013_Fook Island                 0.0  ...                 0.0            0.0   \n",
      "10064_Glubbdubdrib                0.0  ...                 0.0            0.0   \n",
      "1034_Gondal                       0.0  ...                 0.0            0.0   \n",
      "10392_El Othar                    0.0  ...                 0.0            0.0   \n",
      "1046_Glubbdubdrib                 0.0  ...                 0.0            0.0   \n",
      "\n",
      "next_place          6761_Kamistan  7551_Bozatta  8118_Cobra Island  824_Yerba  \\\n",
      "current_place                                                                   \n",
      "10013_Fook Island             0.0           0.0                0.0        0.0   \n",
      "10064_Glubbdubdrib            0.0           0.0                0.0        0.0   \n",
      "1034_Gondal                   0.0           0.0                0.0        0.0   \n",
      "10392_El Othar                0.0           0.0                0.0        0.0   \n",
      "1046_Glubbdubdrib             0.0           0.0                0.0        0.0   \n",
      "\n",
      "next_place          8750_Cobra Island  9590_Glubbdubdrib  9608_Fook Island  \\\n",
      "current_place                                                                \n",
      "10013_Fook Island                 0.0                0.0               0.0   \n",
      "10064_Glubbdubdrib                0.0                0.0               0.0   \n",
      "1034_Gondal                       0.0                0.0               0.0   \n",
      "10392_El Othar                    0.0                0.0               0.0   \n",
      "1046_Glubbdubdrib                 0.0                0.0               0.0   \n",
      "\n",
      "next_place          9723_The Devilfire Empire  \n",
      "current_place                                  \n",
      "10013_Fook Island                         0.0  \n",
      "10064_Glubbdubdrib                        0.0  \n",
      "1034_Gondal                               0.0  \n",
      "10392_El Othar                            0.0  \n",
      "1046_Glubbdubdrib                         0.0  \n",
      "\n",
      "[5 rows x 232 columns]\n"
     ]
    }
   ],
   "source": [
    "#Generating Transition Pairs and Calculating Transition Probabilities:\n",
    "# MARKOV CHAINS\n",
    "    \n",
    "transitions = []\n",
    "\n",
    "for chain in trip_chains_df['city_country_chain']:\n",
    "    for i in range(len(chain) - 1):\n",
    "        transitions.append((chain[i], chain[i + 1]))\n",
    "\n",
    "transitions_df = pd.DataFrame(transitions, columns=['current_place', 'next_place'])\n",
    "transition_counts = transitions_df.groupby('current_place')['next_place'].value_counts(normalize=True).unstack(fill_value=0)\n",
    "print(transition_counts.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b3b0753a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    utrip_id  user_id cities_chain countries_chain  trip_duration  \\\n",
      "0  1000643_1  1000643      [62185]       [Axphain]              2   \n",
      "1   100160_2   100160      [49540]    [Novistrana]              2   \n",
      "2  1001776_1  1001776       [4608]  [Glubbdubdrib]              1   \n",
      "3  1001838_2  1001838      [43666]      [Leutonia]              1   \n",
      "4  1002275_1  1002275      [36805]       [Alvonia]              1   \n",
      "\n",
      "  stay_durations device_classes affiliate_ids checkin_months  \\\n",
      "0            [2]      [desktop]         [384]           [10]   \n",
      "1            [2]      [desktop]        [8132]            [8]   \n",
      "2            [1]      [desktop]        [3134]            [8]   \n",
      "3            [1]      [desktop]        [9924]            [6]   \n",
      "4            [1]      [desktop]        [4541]            [9]   \n",
      "\n",
      "  checkin_days_of_week   city_country_chain predict_next_city_country  \n",
      "0                  [5]      [62185_Axphain]             16612_Axphain  \n",
      "1                  [1]   [49540_Novistrana]                      None  \n",
      "2                  [0]  [4608_Glubbdubdrib]                      None  \n",
      "3                  [3]     [43666_Leutonia]                      None  \n",
      "4                  [1]      [36805_Alvonia]                      None  \n"
     ]
    }
   ],
   "source": [
    "#Predicting the Next City-Country and Adding Predictions to DataFrame:\n",
    "\n",
    "def predict_next_place(current_place):\n",
    "    if current_place in transition_counts.index:\n",
    "        return transition_counts.loc[current_place].idxmax()\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "trip_chains_df['predict_next_city_country'] = trip_chains_df['city_country_chain'].apply(\n",
    "    lambda chain: predict_next_place(chain[-1]) if len(chain) > 0 else None)\n",
    "print(trip_chains_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8f87c849",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trip chains written to trip_chains_enhanced_withprednextcity.xlsx\n"
     ]
    }
   ],
   "source": [
    "# Writing the output of the predicted next city to an Excel file\n",
    "output_file = 'trip_chains_enhanced_withprednextcity.xlsx'\n",
    "trip_chains_df.to_excel(output_file, index=False)\n",
    "print(f'Trip chains written to {output_file}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "74451410",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-01 08:32:17.950301: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-06-01 08:32:20.751400: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2024-06-01 08:32:24.315335: E external/local_xla/xla/stream_executor/cuda/cuda_driver.cc:282] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 74ms/step - accuracy: 0.9561 - loss: 2.7967 - val_accuracy: 0.9870 - val_loss: 0.1104\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 43ms/step\n",
      "Accuracy: 1.00\n",
      "Precision: 0.33\n"
     ]
    }
   ],
   "source": [
    "# Simple RNN model\n",
    "\n",
    "# Additional Imports\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import SimpleRNN, Dense, Embedding\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import accuracy_score, precision_score\n",
    "\n",
    "# Function to preprocess data and prepare for RNN\n",
    "def preprocess_data(data):\n",
    "    # Encode the city_country column\n",
    "    label_encoder = LabelEncoder()\n",
    "    data['city_country_encoded'] = label_encoder.fit_transform(data['city_country'])\n",
    "\n",
    "    # Create sequences for RNN\n",
    "    sequences = []\n",
    "    targets = []\n",
    "    for utrip_id, group in data.groupby('utrip_id'):\n",
    "        sequences.append(group['city_country_encoded'].values[:-1])\n",
    "        targets.append(group['city_country_encoded'].values[1:])\n",
    "    \n",
    "    # Pad sequences\n",
    "    max_seq_length = max(len(seq) for seq in sequences)\n",
    "    X = pad_sequences(sequences, maxlen=max_seq_length, padding='post')\n",
    "    y = pad_sequences(targets, maxlen=max_seq_length, padding='post')\n",
    "    \n",
    "    return X, y, label_encoder\n",
    "\n",
    "# Split the data into training and test sets\n",
    "X, y, label_encoder = preprocess_data(train_data)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.02, random_state=42)\n",
    "\n",
    "# Build the RNN model\n",
    "model = Sequential()\n",
    "model.add(Embedding(input_dim=len(label_encoder.classes_), output_dim=50))#, input_length=X_train.shape[1]))\n",
    "model.add(SimpleRNN(100, return_sequences=True))\n",
    "model.add(Dense(len(label_encoder.classes_), activation='softmax'))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train, epochs=1, batch_size=32, validation_split=0.2)\n",
    "\n",
    "# Evaluate the model\n",
    "y_pred = model.predict(X_test)\n",
    "y_pred_classes = y_pred.argmax(axis=-1)\n",
    "\n",
    "# Calculate accuracy and precision\n",
    "accuracy = accuracy_score(y_test.flatten(), y_pred_classes.flatten())\n",
    "precision = precision_score(y_test.flatten(), y_pred_classes.flatten(), average='macro',zero_division=0)\n",
    "\n",
    "print(f\"Accuracy: {accuracy:.2f}\")\n",
    "print(f\"Precision: {precision:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a7fe87f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted results written to predicted_city_results.xlsx\n"
     ]
    }
   ],
   "source": [
    "# Decode the predictions back to city_country names\n",
    "\n",
    "y_test_flat = y_test.flatten()\n",
    "y_pred_flat = y_pred_classes.flatten()\n",
    "y_test_decoded = label_encoder.inverse_transform(y_test_flat)\n",
    "y_pred_decoded = label_encoder.inverse_transform(y_pred_flat)\n",
    "\n",
    "# Create a DataFrame to store the results\n",
    "\n",
    "results_df = pd.DataFrame({\n",
    "    'Actual': y_test_decoded,\n",
    "    'Predicted': y_pred_decoded\n",
    "})\n",
    "\n",
    "# Write the results to an Excel file\n",
    "results_df.to_excel('predicted_city_results.xlsx', index=False)\n",
    "print(\"Predicted results written to predicted_city_results.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec85667c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
